{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *[Using AutoML as a start point]*\n",
    "\n",
    "**Author:** [Marco Bertani-Ã˜kland](https://github.com/mbertani)\n",
    "\n",
    "**Achievement:** Illustrate the use of AutoML as a starting point to explore different algorithms.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook is based on [https://supervised.mljar.com/](https://supervised.mljar.com/).\n",
    "\n",
    "Run the notebook and check the results produced under the folder `results_diabetes`. \n",
    "\n",
    "Requirements:\n",
    "\n",
    "1. You must run `make venv` to verify that all packages are installed.\n",
    "2. You must have downloaded the [diabetes dataset](https://www.kaggle.com/datasets/alexteboul/diabetes-health-indicators-dataset) into the folder `NBD_22_workshop`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproducibility and code formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To watermark the environment\n",
    "%load_ext watermark\n",
    "\n",
    "# For automatic code formatting in jupyter lab.\n",
    "%load_ext lab_black\n",
    "\n",
    "# For automatic code formatting in jupyter notebook\n",
    "%load_ext nb_black\n",
    "\n",
    "# For better logging\n",
    "%load_ext rich"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "# -------\n",
    "\n",
    "# System\n",
    "import sys\n",
    "\n",
    "# Logging\n",
    "import logging\n",
    "\n",
    "# Rich logging in jupyter\n",
    "from rich.logging import RichHandler\n",
    "\n",
    "FORMAT = \"%(message)s\"\n",
    "logging.basicConfig(\n",
    "    level=\"INFO\", format=FORMAT, datefmt=\"[%X]\", handlers=[RichHandler()]\n",
    ")\n",
    "\n",
    "log = logging.getLogger(\"rich\")\n",
    "\n",
    "# Nice logging example:\n",
    "# log.error(\"[bold red blink]Server is shutting down![/]\", extra={\"markup\": True})\n",
    "\n",
    "\n",
    "# Other packages\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from supervised.automl import AutoML\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load the training dataset\n",
    "datapath = \"../data/train/diabetes_binary_train.csv.zip\"\n",
    "df = pd.read_csv(datapath, compression=\"zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we create the list of columns we will use for training\n",
    "target_column = \"Diabetes_binary\"\n",
    "train_columns = list(df.columns)\n",
    "train_columns.remove(target_column)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    df[train_columns], df[target_column], test_size=0.2, random_state=RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the AutoML package, we configure it for binary classification. The package has several [modes](https://supervised.mljar.com/features/modes/), and we use `Perform` for real life scenarios. We chose some [algorithms](https://supervised.mljar.com/features/algorithms/) to start with, but have a look at the list of available ones, if you want to experiment with others (beware: no all can be used for the binary classification setup).\n",
    "\n",
    "We have also changed the default metric to `accuracy`, and set the [start_random_models=5](https://supervised.mljar.com/features/automl/#not_so_random) to perform random search over some hyper-parameters. We also turn off the `train_ensemble` option, which will use an ensemble of previous models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the AutoML package, we configure it for binary classification\n",
    "automl = AutoML(\n",
    "    results_path=\"experiment-full\",\n",
    "    mode=\"Perform\",\n",
    "    ml_task=\"binary_classification\",\n",
    "    algorithms=[\n",
    "        \"LightGBM\",\n",
    "        \"Extra Trees\",\n",
    "        \"CatBoost\",\n",
    "        \"Baseline\",\n",
    "        \"Decision Tree\",\n",
    "        \"Neural Network\",\n",
    "    ],\n",
    "    eval_metric=\"accuracy\",\n",
    "    start_random_models=5,\n",
    "    total_time_limit=1500,\n",
    "    train_ensemble=False,\n",
    "    random_state=RANDOM_SEED,\n",
    ")\n",
    "model = automl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = automl.predict(X_valid)\n",
    "print(\n",
    "    f\"Best model accuracy score on validation set: {accuracy_score(y_valid,predictions):.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving the experimentation\n",
    "\n",
    "In the previous step, we used the full dataset. But what about using only the columns where the predictive power score was highest? We can sort those columns by the power score ranking, run the auto-ml pipeline for the first column and find the best model. Then we add a new column and repeat. When do we get a similar perfomance than when using the full dataset?\n",
    "\n",
    "In this way, we prune the features by creating a simpler model, and less data dependencies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "def automl_pipeline(\n",
    "    frame: pd.DataFrame,\n",
    "    train_columns: List[str],\n",
    "    target_column: str,\n",
    "    results_path: str,\n",
    "    random_search_iterations: int,\n",
    "    max_total_time: int,\n",
    "    random_state: int = RANDOM_SEED,\n",
    ") -> AutoML:\n",
    "    \"\"\"Create a simple pipeline that will create the train and eval splits on the selected columns and run the auto-ml process.\n",
    "\n",
    "    Args:\n",
    "        frame (pd.DataFrame): The input dataset to be split.\n",
    "        train_columns (List[str]): A list of columns to use for training.\n",
    "        target_column (str): The target column to predict.\n",
    "        results_path (str): A name for the folder to store the results.\n",
    "        random_search_iterations (int): The number of random search hyper-params trials to run.\n",
    "        random_state (int, optional): The random seed to fix the pseudo-random number generators. Defaults to RANDOM_SEED.\n",
    "\n",
    "    Returns:\n",
    "        AutoML: an AutoML object containing the best model for each run.\n",
    "    \"\"\"\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        frame[train_columns],\n",
    "        frame[target_column],\n",
    "        test_size=0.2,\n",
    "        random_state=RANDOM_SEED,\n",
    "    )\n",
    "\n",
    "    automl = AutoML(\n",
    "        results_path=results_path,\n",
    "        mode=\"Perform\",\n",
    "        ml_task=\"binary_classification\",\n",
    "        algorithms=[\n",
    "            \"Baseline\",\n",
    "            \"Decision Tree\",\n",
    "            \"Extra Trees\",\n",
    "            \"LightGBM\",\n",
    "            \"CatBoost\",\n",
    "            \"Neural Network\",\n",
    "        ],\n",
    "        eval_metric=\"accuracy\",\n",
    "        start_random_models=random_search_iterations,\n",
    "        train_ensemble=False,\n",
    "        total_time_limit=max_total_time,\n",
    "        random_state=RANDOM_SEED,\n",
    "    )\n",
    "\n",
    "    model = automl.fit(X_train, y_train)\n",
    "    predictions = automl.predict(X_valid)\n",
    "    log.info(\n",
    "        f\"Best model accuracy_score on valid set: {accuracy_score(y_valid,predictions):.3f}\"\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def experiment_pipeline(\n",
    "    name: str,\n",
    "    target_column: str,\n",
    "    sorted_columns: List[str],\n",
    "    frame: pd.DataFrame,\n",
    "    random_search_iterations: int = 5,\n",
    "    max_total_time: int = 1500,\n",
    "    random_state: int = RANDOM_SEED,\n",
    ") -> List[AutoML]:\n",
    "    \"\"\"A method to run several iterations of an AutoML process.\n",
    "\n",
    "    Args:\n",
    "        name (str): The name to use as prefix for the results folder. The folders will be created using format `<name>-<index>`.\n",
    "        target_column (str): The column with the feature to predict.\n",
    "        sorted_columns (List[str]): A sorted list of feature columns. The process will start by runing an AutoML process for the first column for training, and add the next one for the next iteration.\n",
    "        frame (pd.DataFrame): The dataFrame with all the data, not split beforehand.\n",
    "        random_search_iterations (int): The number of random search hyper-params trials to run.\n",
    "        max_total_time (int): The max number of seconds the experiment can run for. Default is 1500 seconds (25 mins).\n",
    "        random_state (int, optional): The random seed to fix the pseudo-random number generators. Defaults to RANDOM_SEED.\n",
    "\n",
    "    Returns:\n",
    "        List[AutoML]: A sorted list of AutoML objects.\n",
    "    \"\"\"\n",
    "    best_models = []\n",
    "    for iteration in range(1, len(sorted_columns) + 1):\n",
    "        experiment = f\"{name}-{iteration}\"\n",
    "        log.info(f\"Starting: {experiment}\")\n",
    "        train_columns = sorted_columns[0:iteration]\n",
    "        log.info(f\"Training on features: {train_columns}\")\n",
    "        automl_model = automl_pipeline(\n",
    "            frame=df,\n",
    "            train_columns=train_columns,\n",
    "            target_column=target_column,\n",
    "            results_path=experiment,\n",
    "            random_search_iterations=random_search_iterations,\n",
    "            max_total_time=max_total_time,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "        best_models.append(automl_model)\n",
    "        log.info(f\"Ending: {experiment}\\n\")\n",
    "\n",
    "    return best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's run the experiments.\n",
    "# Grab a coffee since this will take some time.\n",
    "best_models = experiment_pipeline(\n",
    "    name=\"experiment\",\n",
    "    target_column=\"Diabetes_binary\",\n",
    "    sorted_columns=[\"HighBP\", \"GenHlth\", \"HighChol\", \"BMI\", \"Age\", \"Income\"],\n",
    "    random_search_iterations=1,\n",
    "    max_total_time=150,\n",
    "    frame=df,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath_test = \"../data/train/diabetes_binary_test.csv.zip\"\n",
    "df_test = pd.read_csv(datapath, compression=\"zip\")\n",
    "target_column = \"Diabetes_binary\"\n",
    "train_columns = list(df.columns)\n",
    "train_columns.remove(target_column)\n",
    "X_test, y_test = df_test[train_columns], df_test[target_column]\n",
    "\n",
    "predictions = best_models[-1].predict(X_test)\n",
    "log.info(\n",
    "    f\"Best model accuracy score on test set: {accuracy_score(y_test,predictions):.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watermark\n",
    "\n",
    "This should be the last section of your notebook, since it watermarks all your environment.\n",
    "\n",
    "When commiting this notebook, remember to restart the kernel, rerun the notebook and run this cell last, to watermark the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%watermark -gb -iv -m -v"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ml_automl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "fc29e3cf0988d071a972b3d784b67eb2dc4190413be0b229c97e65f78ba8c81b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
